{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d90a81-2f65-49ba-b080-9ecac6c5a08d",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation\n",
    "* LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a90309d-20f3-4084-9511-82ee314d676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6240d78c-663a-4fca-afe9-18b58e099a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4049a-dfb1-445a-879a-f55dc6000308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e9538e0-9cc2-47f6-82d6-8f16ee547211",
   "metadata": {},
   "source": [
    "## Create our Q&A application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5eb4c9-6571-469a-a899-bf9a2960aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush.nema/Documents/pyenvs/LLMCompass/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192afa9-3c2f-426e-8d95-c0c2ec83db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e0f03-b45c-4411-838a-88f35fb3dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84e6b6-04b2-403f-a5cf-a43d00d8b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    verbose=True,\n",
    "    chain_type_kwargs = {\n",
    "        \"document_separator\": \"<<<<>>>>>\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920bb29-413b-46a9-a4a2-5d64326263cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be67ed87-1a5b-448c-bd7a-d723ed57488e",
   "metadata": {},
   "source": [
    "### Coming up with test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624b3b7-1f6b-481c-961a-800a0e2f5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddf279-a05d-4e8f-8836-7cd5fe09267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65f5eb-93f5-453b-ba68-542839de4b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d07e87d-c43f-417d-9d20-0c125480c2f2",
   "metadata": {},
   "source": [
    "### Hardcoded examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db29f4d-9696-4efd-8cc8-3efae7cb5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
    "        have side pockets?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What collection is the Ultra-Lofty \\\n",
    "        850 Stretch Down Hooded Jacket from?\",\n",
    "        \"answer\": \"The DownTek collection\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60daa3f4-2374-425d-8edc-b83c1d060fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e0a955-5215-466a-bc5e-59ed11186362",
   "metadata": {},
   "source": [
    "### LLM-generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eefeee4-5736-4206-9cfe-623b3b6286a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d414d5-4f90-4525-954b-16a261494236",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model=llm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc3e231-597d-4262-b328-24920242f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warning below can be safely ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82fd5c-b4ca-4774-8f98-b8fff822f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples = example_gen_chain.apply_and_parse([{\"doc\": t} for t in data[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93659a8e-a44d-4ba1-bf9c-28e046e33108",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acde8c2-ece3-450e-ae26-e363f6c51481",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168ce2c-0392-4318-adb6-0e9c37a26f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af58bd3-aefc-49cb-a92f-b13531455f61",
   "metadata": {},
   "source": [
    "### Combine examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af901906-5774-4432-8762-5ef755246078",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples += new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cecec-4663-4bba-8dbb-70b288476269",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c910102-6688-4d5e-a5a0-c06ced70405f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ccabe79-19d2-454c-84dc-452601a9a73f",
   "metadata": {},
   "source": [
    "## Manual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6c4351-54a7-40ea-845d-0eec2fc6bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c90ef-1f10-408d-9005-0a3353ba8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(examples[0]['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e14a17-cbfe-45ab-ae3a-ad31e9756a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332568c1-a59a-4a96-b1d8-0fca7dddc5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae8f17e-c1cd-46b0-bd7d-3aa87a8eb383",
   "metadata": {},
   "source": [
    "## LLM assisted evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4dbdfe-96ae-4741-b1e4-610c0e07c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qa.apply(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08620826-1bcf-4999-9436-73520ba41e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a076288-51b8-4c0e-aab7-6016ad07dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "eval_chain = QAEvalChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceff2ff-c16b-442b-b881-9f8048498191",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7bba2-bec0-48e5-b61f-d00b8ebb4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, eg in enumerate(examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015b42a-49be-4f44-8b50-e529a1b083f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05b810-cdb8-4f7a-a47d-de113c2e1b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8ca1ce2-6ae5-4d48-876d-5734ec1cb129",
   "metadata": {},
   "source": [
    "## LangChain evaluation platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde74f2-3c72-4b4f-b1f7-e607df6e976f",
   "metadata": {},
   "source": [
    "The LangChain evaluation platform, LangChain Plus, can be accessed here https://www.langchain.plus/. Use the invite code `lang_learners_2023`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641a7c0-1648-4e9b-bbd4-d7b6c901f094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMCompass",
   "language": "python",
   "name": "llmcompass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
